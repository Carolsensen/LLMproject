{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ff19060-dd0b-4527-9088-7f90b17e7026",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import random\n",
    "from datasketch import MinHash, MinHashLSH\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75dbe5d9-aa18-42b1-a51c-c3f27e9564d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 9007 Chinese tourism QA pairs\n",
      "Loaded 53280 NW tourism items\n",
      "Detected cities in NW data: ['木盖库勒', '份乃至国际', '胜利纪念园景区', '也是游客和', '而西北部', '以了解白银', '在藏于汉中', '县姜州花湖景区', '构成了长春', '院所在的城']... (total: 38788)\n",
      "Sampled 4000 NW tourism items from 35076 categories\n",
      "Combined data: 13007 items\n",
      "Deduplication: 12627/13007 items kept (2.92% duplication)\n",
      "Saved 12627 items to tourism_lora_data3.jsonl\n",
      "Quality report saved to data_quality3.md\n",
      "\n",
      "Sample data:\n",
      "{\n",
      "  \"messages\": [\n",
      "    {\n",
      "      \"role\": \"system\",\n",
      "      \"content\": \"你是一名专业的旅游助手，熟悉中国各地旅游景点和行程规划\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": \"请问南宁饭店是几星级酒店？\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": \"/no_think 南宁饭店是一家４星级酒店，位于南宁市中心，拥有现代化的设施和优质的服务。酒店提供舒适的客房、美味的餐饮和完善的会议设施。我们的客房宽敞明亮，装饰精美，配备了舒适的床铺、豪华的卫浴设施以及免费的无线网络连接。酒店的餐厅供应各种美食，包括当地特色菜肴和国际美食。我们还为商务旅客提供先进的会议设施，包括宽敞的会议室和高科技的音视频设备。无论您是来南宁旅行还是商务出差，南宁饭店都会给您提供一个舒适、便利的住宿体验。欢迎您的光临！\"\n",
      "    }\n",
      "  ],\n",
      "  \"no_think\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# === 1. 配置参数 ===\n",
    "TARGET_CITIES = [\n",
    "    '西安', '兰州', '敦煌', '乌鲁木齐', '银川', '西宁', '张掖', '嘉峪关',\n",
    "    '天水', '酒泉', '武威', '金昌', '白银', '庆阳', '平凉', '定西', '陇南'\n",
    "]\n",
    "MAX_SAMPLES = 14000\n",
    "DUPE_THRESHOLD = 0.85\n",
    "\n",
    "# === 2. 加载中文旅游监督数据集 ===\n",
    "def load_cn_tourism(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                item = json.loads(line)\n",
    "                data.append({\n",
    "                    \"conversations\": [\n",
    "                        {\"role\": \"user\", \"content\": item['prompt']},\n",
    "                        {\"role\": \"assistant\", \"content\": f\"/no_think {item['response']}\"}\n",
    "                    ]\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading CN item: {e}\")\n",
    "                continue\n",
    "    print(f\"Loaded {len(data)} Chinese tourism QA pairs\")\n",
    "    return data\n",
    "\n",
    "# === 3. 加载并抽样西北数据集 ===\n",
    "def load_nw_tourism(file_path, sample_size=4000):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            nw_data = json.load(f)\n",
    "        print(f\"Loaded {len(nw_data)} NW tourism items\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading NW data: {e}\")\n",
    "        return []\n",
    "    \n",
    "    # 自动提取数据中的所有城市\n",
    "    all_cities = set()\n",
    "    for item in nw_data:\n",
    "        # 从instruction中提取城市\n",
    "        instruction = item.get('instruction', '')\n",
    "        city_match = re.search(r'^(.*?)(市|地区|景区|景点|旅游)', instruction)\n",
    "        if city_match and len(city_match.group(1)) >= 2:\n",
    "            all_cities.add(city_match.group(1))\n",
    "        \n",
    "        # 从output中提取城市\n",
    "        output = item.get('output', '')\n",
    "        cities_in_output = re.findall(r'([\\u4e00-\\u9fa5]{2,5}?(?:市|地区|景区|景点))', output)\n",
    "        for city in cities_in_output:\n",
    "            all_cities.add(city.replace('市', '').replace('地区', ''))\n",
    "    \n",
    "    print(f\"Detected cities in NW data: {list(all_cities)[:10]}... (total: {len(all_cities)})\")\n",
    "    \n",
    "    # 创建城市映射：将检测到的城市映射到目标城市\n",
    "    city_mapping = {}\n",
    "    for city in all_cities:\n",
    "        # 检查是否属于目标城市\n",
    "        for target_city in TARGET_CITIES:\n",
    "            if target_city in city:\n",
    "                city_mapping[city] = target_city\n",
    "                break\n",
    "        # 如果未匹配，保留原城市名\n",
    "        if city not in city_mapping:\n",
    "            city_mapping[city] = city\n",
    "    \n",
    "    # 按城市分组数据\n",
    "    city_items = {city: [] for city in set(city_mapping.values())}\n",
    "    for item in nw_data:\n",
    "        # 确定城市\n",
    "        instruction = item.get('instruction', '')\n",
    "        for origin_city, mapped_city in city_mapping.items():\n",
    "            if origin_city in instruction:\n",
    "                city_items[mapped_city].append(item)\n",
    "                break\n",
    "        else:\n",
    "            # 如果未匹配，分配到\"其他\"类别\n",
    "            city_items.setdefault('其他', []).append(item)\n",
    "    \n",
    "    # 分层抽样\n",
    "    sampled_items = []\n",
    "    min_per_city = max(1, sample_size // len(city_items))\n",
    "    \n",
    "    for city, items in city_items.items():\n",
    "        # 确保每个城市至少有min_per_city条数据\n",
    "        if len(items) > min_per_city:\n",
    "            sampled_items.extend(random.sample(items, min_per_city))\n",
    "        else:\n",
    "            sampled_items.extend(items)\n",
    "    \n",
    "    # 如果不足，补充随机样本\n",
    "    if len(sampled_items) < sample_size:\n",
    "        remaining = sample_size - len(sampled_items)\n",
    "        all_items = [item for sublist in city_items.values() for item in sublist]\n",
    "        sampled_items.extend(random.sample(all_items, min(remaining, len(all_items))))\n",
    "    \n",
    "    print(f\"Sampled {len(sampled_items)} NW tourism items from {len(city_items)} categories\")\n",
    "    \n",
    "    # 转换为标准格式\n",
    "    converted_data = []\n",
    "    for item in sampled_items:\n",
    "        # 处理可能的空字段\n",
    "        instruction = item.get('instruction', '')\n",
    "        input_text = item.get('input', '')\n",
    "        output = item.get('output', '')\n",
    "        \n",
    "        # 构建用户内容\n",
    "        user_content = instruction\n",
    "        if input_text.strip():\n",
    "            user_content += f\"\\n{input_text}\"\n",
    "        \n",
    "        # 处理空输出\n",
    "        if not output.strip():\n",
    "            output = \"该旅游信息暂缺，请咨询当地旅游局\"\n",
    "        \n",
    "        converted_data.append({\n",
    "            \"conversations\": [\n",
    "                {\"role\": \"user\", \"content\": user_content},\n",
    "                {\"role\": \"assistant\", \"content\": f\"/no_think {output}\"}\n",
    "            ]\n",
    "        })\n",
    "    \n",
    "    return converted_data\n",
    "\n",
    "# === 4. MinHash去重 ===\n",
    "def deduplicate(data, threshold=DUPE_THRESHOLD):\n",
    "    lsh = MinHashLSH(threshold=threshold, num_perm=128)\n",
    "    unique_data = []\n",
    "    \n",
    "    for idx, item in enumerate(data):\n",
    "        assistant_content = item['conversations'][1]['content']\n",
    "        \n",
    "        # 创建MinHash指纹\n",
    "        m = MinHash(num_perm=128)\n",
    "        words = jieba.lcut(assistant_content)[:50]  # 使用结巴分词\n",
    "        for word in words:\n",
    "            m.update(word.encode('utf-8'))\n",
    "        \n",
    "        # 检查是否重复\n",
    "        if not lsh.query(m):\n",
    "            lsh.insert(f\"item_{idx}\", m)\n",
    "            unique_data.append(item)\n",
    "    \n",
    "    dup_rate = (1 - len(unique_data)/len(data)) * 100\n",
    "    print(f\"Deduplication: {len(unique_data)}/{len(data)} items kept ({dup_rate:.2f}% duplication)\")\n",
    "    return unique_data\n",
    "\n",
    "# === 5. 生成LoRA训练格式 ===\n",
    "def convert_to_lora_format(data):\n",
    "    lora_data = []\n",
    "    for item in data:\n",
    "        # 构建多轮对话格式\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"你是一名专业的旅游助手，熟悉中国各地旅游景点和行程规划\"},\n",
    "            {\"role\": \"user\", \"content\": item['conversations'][0]['content']},\n",
    "            {\"role\": \"assistant\", \"content\": item['conversations'][1]['content']}\n",
    "        ]\n",
    "        \n",
    "        lora_data.append({\n",
    "            \"messages\": messages,\n",
    "            \"no_think\": True  # 启用快速响应模式\n",
    "        })\n",
    "    return lora_data\n",
    "\n",
    "# === 6. 生成质量报告 ===\n",
    "def generate_quality_report(data, output_file):\n",
    "    # 1. 基本统计\n",
    "    total_items = len(data)\n",
    "    word_counts = []\n",
    "    city_coverage = {city: 0 for city in TARGET_CITIES}\n",
    "    \n",
    "    # 2. 关键词分析\n",
    "    keywords = [\"景点\", \"酒店\", \"交通\", \"美食\", \"攻略\", \"行程\", \"推荐\", \"门票\"]\n",
    "    keyword_coverage = {kw: 0 for kw in keywords}\n",
    "    \n",
    "    # 3. 遍历数据\n",
    "    for item in data:\n",
    "        content = json.dumps(item)\n",
    "        \n",
    "        # 城市覆盖统计\n",
    "        for city in TARGET_CITIES:\n",
    "            if city in content:\n",
    "                city_coverage[city] += 1\n",
    "        \n",
    "        # 关键词统计\n",
    "        for kw in keywords:\n",
    "            if kw in content:\n",
    "                keyword_coverage[kw] += 1\n",
    "        \n",
    "        # 词数统计\n",
    "        assistant_text = item['messages'][-1]['content']\n",
    "        word_counts.append(len(jieba.lcut(assistant_text)))\n",
    "    \n",
    "    # 4. 生成报告\n",
    "    report = f\"# 旅游数据集质量报告\\n\\n\"\n",
    "    report += f\"**总样本量**: {total_items}\\n\"\n",
    "    report += f\"**平均回复长度**: {sum(word_counts)/len(word_counts):.1f} 词\\n\\n\"\n",
    "    \n",
    "    report += \"## 城市覆盖统计\\n\"\n",
    "    for city, count in city_coverage.items():\n",
    "        coverage_pct = (count / total_items) * 100\n",
    "        report += f\"- {city}: {count} 条 ({coverage_pct:.1f}%)\\n\"\n",
    "    \n",
    "    report += \"\\n## 关键词覆盖率\\n\"\n",
    "    for kw, count in keyword_coverage.items():\n",
    "        coverage_pct = (count / total_items) * 100\n",
    "        report += f\"- {kw}: {coverage_pct:.1f}%\\n\"\n",
    "    \n",
    "    # 5. 保存报告\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(report)\n",
    "    print(f\"Quality report saved to {output_file}\")\n",
    "\n",
    "# === 主流程 ===\n",
    "if __name__ == \"__main__\":\n",
    "    # 加载数据集\n",
    "    cn_data = load_cn_tourism(\"merge.jsonl\")\n",
    "    nw_data = load_nw_tourism(\"LLMTourism.json\")\n",
    "    \n",
    "    # 合并数据\n",
    "    combined_data = cn_data + nw_data\n",
    "    print(f\"Combined data: {len(combined_data)} items\")\n",
    "    \n",
    "    # 去重\n",
    "    deduped_data = deduplicate(combined_data)\n",
    "    \n",
    "    # 转换为LoRA格式\n",
    "    lora_data = convert_to_lora_format(deduped_data[:MAX_SAMPLES])\n",
    "    \n",
    "    # 保存最终数据集\n",
    "    output_file = \"tourism_lora_data3.jsonl\"\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        for item in lora_data:\n",
    "            f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
    "    print(f\"Saved {len(lora_data)} items to {output_file}\")\n",
    "    \n",
    "    # 生成质量报告\n",
    "    generate_quality_report(lora_data, \"data_quality3.md\")\n",
    "    \n",
    "    # 打印样本检查\n",
    "    print(\"\\nSample data:\")\n",
    "    print(json.dumps(lora_data[0], indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b65566f-d429-40b8-b066-c01d7f90bc30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前数据城市分布:\n",
      "天水: 73条\n",
      "张掖: 60条\n",
      "西安: 133条\n",
      "南宁: 638条\n"
     ]
    }
   ],
   "source": [
    "city_check = ['天水', '张掖', '西安', '南宁']  # 您关心的城市\n",
    "\n",
    "with open('tourism_lora_data3.jsonl', 'r', encoding='utf-8') as f:\n",
    "    counts = {city:0 for city in city_check}\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        text = str(data)\n",
    "        for city in city_check:\n",
    "            if city in text:\n",
    "                counts[city] += 1\n",
    "\n",
    "print(\"当前数据城市分布:\")\n",
    "for city, count in counts.items():\n",
    "    print(f\"{city}: {count}条\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e03bcd43-b0e4-4da4-aa57-7262068e8779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "天水: 73条\n",
      "张掖: 60条\n",
      "兰州: 175条\n"
     ]
    }
   ],
   "source": [
    "# 检查西北数据是否真的被包含\n",
    "import pandas as pd\n",
    "df = pd.read_json('tourism_lora_data3.jsonl', lines=True)\n",
    "\n",
    "# 检查目标城市出现次数\n",
    "for city in ['天水', '张掖', '兰州']:\n",
    "    count = df['messages'].apply(lambda x: city in str(x)).sum()\n",
    "    print(f\"{city}: {count}条\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e5f0bad-9050-4f8a-a24e-c8d7b0836f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 更新generate_quality_report函数（替换原函数）\n",
    "def generate_quality_report(data, output_file):\n",
    "    # 真实城市列表（与检测逻辑保持一致）\n",
    "    REAL_CITIES = ['西安','兰州','敦煌','乌鲁木齐','银川','西宁',\n",
    "                  '张掖','嘉峪关','天水','酒泉','武威','金昌',\n",
    "                  '白银','庆阳','平凉','定西','陇南','南宁']\n",
    "    \n",
    "    # 关键词列表\n",
    "    KEYWORDS = [\"景点\", \"酒店\", \"交通\", \"美食\", \"攻略\", \n",
    "               \"行程\", \"推荐\", \"门票\", \"住宿\", \"餐厅\"]\n",
    "    \n",
    "    # 初始化统计\n",
    "    city_counts = {city: 0 for city in REAL_CITIES}\n",
    "    keyword_counts = {kw: 0 for kw in KEYWORDS}\n",
    "    total_length = 0\n",
    "    \n",
    "    for item in data:\n",
    "        # 提取所有文本内容\n",
    "        messages = item.get('messages', [])\n",
    "        text = \" \".join([msg['content'] for msg in messages if isinstance(msg, dict)])\n",
    "        \n",
    "        # 统计城市\n",
    "        for city in REAL_CITIES:\n",
    "            if city in text:\n",
    "                city_counts[city] += 1\n",
    "        \n",
    "        # 统计关键词\n",
    "        for kw in KEYWORDS:\n",
    "            if kw in text:\n",
    "                keyword_counts[kw] += 1\n",
    "        \n",
    "        # 计算回复长度\n",
    "        if len(messages) >= 3:  # 确保有assistant回复\n",
    "            assistant_text = messages[2]['content']\n",
    "            total_length += len(jieba.lcut(assistant_text))\n",
    "    \n",
    "    # 生成报告\n",
    "    report = [\n",
    "        \"# 旅游数据集质量报告\",\n",
    "        f\"**总样本量**: {len(data)}\",\n",
    "        f\"**平均回复长度**: {total_length/len(data):.1f} 词\\n\",\n",
    "        \"## 城市覆盖统计\"\n",
    "    ]\n",
    "    \n",
    "    # 按城市数量降序排列\n",
    "    sorted_cities = sorted(\n",
    "        [(city, count) for city, count in city_counts.items() if count > 0],\n",
    "        key=lambda x: -x[1]\n",
    "    )\n",
    "    \n",
    "    for city, count in sorted_cities:\n",
    "        report.append(f\"- {city}: {count} 条 ({count/len(data)*100:.1f}%)\")\n",
    "    \n",
    "    report.extend([\n",
    "        \"\\n## 关键词覆盖率\",\n",
    "        \"| 关键词 | 出现次数 | 覆盖率 |\",\n",
    "        \"|--------|---------|--------|\"\n",
    "    ])\n",
    "    \n",
    "    for kw in KEYWORDS:\n",
    "        count = keyword_counts[kw]\n",
    "        coverage = count/len(data)*100\n",
    "        report.append(f\"| {kw} | {count} | {coverage:.1f}% |\")\n",
    "    \n",
    "    # 保存报告\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"\\n\".join(report))\n",
    "    \n",
    "    print(f\"重新生成的质量报告已保存到 {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7277b8aa-0cb6-4bca-8e1c-471813da1c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "重新生成的质量报告已保存到 data_quality_fixed.md\n",
      "天水数据示例:\n",
      "{\n",
      "  \"messages\": [\n",
      "    {\n",
      "      \"role\": \"system\",\n",
      "      \"content\": \"你是一名专业的旅游助手，熟悉中国各地旅游景点和行程规划\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": \"请问百里柳江的门票价格是多少呢？\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": \"/no_think 百里柳江的门票价格根据不同类型的船只而有所不同。柳航1号船的船票价格为80元，而画舫龙船的船票则是100元。此外，如果您选择乘坐白天水上公交游览百里柳江，单程票价为3元。\\n百里柳江是一个美丽的水上景区，游客可以选择不同的船只来欣赏江边美景。柳航1号船适合喜欢舒适体验的游客，而画舫龙船则展现了独特的文化韵味。白天水上公交则是一种便捷的交通选择，可以让您舒适地游览整个景区。\\n在购买门票时，您可以根据个人的喜好和需求选择适合自己的船只。不同类型的船票会提供不同的船上体验，您可以根据自己的偏好做出选择。\\n如果您想要更加深入地了解百里柳江的游览项目和服务，也可以前往景区的服务中心或官方网站查询更多信息。希望您在百里柳江的游览中有一个愉快而难忘的体验！\"\n",
      "    }\n",
      "  ],\n",
      "  \"no_think\": true\n",
      "}\n",
      "---\n",
      "{\n",
      "  \"messages\": [\n",
      "    {\n",
      "      \"role\": \"system\",\n",
      "      \"content\": \"你是一名专业的旅游助手，熟悉中国各地旅游景点和行程规划\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": \"古象温泉度假村有哪些主要景点呢？\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": \"/no_think 在来宾市象州古象温泉度假村，您将发现各种迷人的景点和设施。首先是19个不同类型的温泉泡池，包括特色温泉泡池、温泉游泳池、儿童戏水池以及独立贵宾温泉池。这些泡池可同时容纳1500多人泡浴，无论您是寻求放松抑或享受水疗体验，都能找到合适的选择。\\n除了温泉设施外，度假村还设有健身中心，供应美味健康的饮食、放松身心的休息厅以及露天水吧。这些配套设施让您在享受温泉的同时，也能尽情放松，体验全方位的度假乐趣。\\n不仅如此，古象温泉度假村还提供各种娱乐活动和服务，让您的旅程更加丰富多彩。您可以参加户外探险、观赏精彩表演，或者在花园漫步，感受大自然的宁静与美好。\\n总体来说，古象温泉度假村拥有丰富多样的景点和设施，适合各种客人的需求，无论您是来放松、享受温泉，还是寻求娱乐活动和精彩体验，这里都能满足您的期待。\"\n",
      "    }\n",
      "  ],\n",
      "  \"no_think\": true\n",
      "}\n",
      "---\n",
      "{\n",
      "  \"messages\": [\n",
      "    {\n",
      "      \"role\": \"system\",\n",
      "      \"content\": \"你是一名专业的旅游助手，熟悉中国各地旅游景点和行程规划\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": \"请问兴坪古镇核心景区都有哪些著名景点呢？\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": \"/no_think 在兴坪古镇核心景区，有九马画山、螺丝山、莲花岩、天水寨、灵宝阁、兴坪古街、老寨山友好亭、总统渔村、黄布滩、罗田大岩、西塘天湖、崧坪龙、腾蛟庵、大源林场、二十元人民币背景——大河背风光等八大景区，共计24个风景点。你可以一一欣赏这些景点的独特之处，例如九马画山以其响马而得名，莲花岩则以其奇特的岩石造型吸引游客的目光。总统渔村则是因曾接待过总统而闻名，可以品味到特色的渔村文化和美味的海鲜。兴坪古街是古镇的主要街道，有着浓厚的历史文化氛围，非常适合闲逛和购物。西塘天湖则是一个湖泊风景区，湖光山色尽收眼底，非常宜人。在你的游览过程中，你还可以欣赏到罗田大岩的奇特地貌，感受大源林场的森林氛围以及大河背风光的壮美。希望你在兴坪古镇的旅行中能够尽情享受这些著名景点带来的美妙体验！\"\n",
      "    }\n",
      "  ],\n",
      "  \"no_think\": true\n",
      "}\n",
      "---\n",
      "包含'景点'的数据量: 12627\n"
     ]
    }
   ],
   "source": [
    "# 加载现有数据\n",
    "with open('tourism_lora_data3.jsonl', 'r', encoding='utf-8') as f:\n",
    "    lora_data = [json.loads(line) for line in f]\n",
    "\n",
    "# 生成新报告\n",
    "generate_quality_report(lora_data, 'data_quality_fixed.md')\n",
    "\n",
    "# 检查天水数据示例\n",
    "tianshui_samples = [\n",
    "    item for item in lora_data \n",
    "    if '天水' in str(item.get('messages', []))\n",
    "][:3]\n",
    "print(\"天水数据示例:\")\n",
    "for sample in tianshui_samples:\n",
    "    print(json.dumps(sample, indent=2, ensure_ascii=False))\n",
    "    print(\"---\")\n",
    "\n",
    "# 检查\"景点\"关键词出现情况\n",
    "jingdian_samples = [\n",
    "    item for item in lora_data \n",
    "    if '景点' in str(item.get('messages', []))\n",
    "]\n",
    "print(f\"包含'景点'的数据量: {len(jingdian_samples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6164b3-1e09-4013-833b-66938a91dbb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
