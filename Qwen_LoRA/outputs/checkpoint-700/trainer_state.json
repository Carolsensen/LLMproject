{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.8869179600886918,
  "eval_steps": 500,
  "global_step": 700,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.012670256572695597,
      "grad_norm": 9.015233993530273,
      "learning_rate": 6.329113924050633e-06,
      "loss": 6.0362,
      "step": 10
    },
    {
      "epoch": 0.025340513145391194,
      "grad_norm": 21.176952362060547,
      "learning_rate": 1.2658227848101267e-05,
      "loss": 5.8275,
      "step": 20
    },
    {
      "epoch": 0.03801076971808679,
      "grad_norm": 20.41964340209961,
      "learning_rate": 1.89873417721519e-05,
      "loss": 4.708,
      "step": 30
    },
    {
      "epoch": 0.05068102629078239,
      "grad_norm": 6.1711602210998535,
      "learning_rate": 2.5316455696202533e-05,
      "loss": 2.7484,
      "step": 40
    },
    {
      "epoch": 0.06335128286347799,
      "grad_norm": 2.119091033935547,
      "learning_rate": 3.1645569620253167e-05,
      "loss": 1.7135,
      "step": 50
    },
    {
      "epoch": 0.07602153943617358,
      "grad_norm": 1.5266077518463135,
      "learning_rate": 3.79746835443038e-05,
      "loss": 1.4308,
      "step": 60
    },
    {
      "epoch": 0.08869179600886919,
      "grad_norm": 0.5316480398178101,
      "learning_rate": 4.430379746835443e-05,
      "loss": 1.2471,
      "step": 70
    },
    {
      "epoch": 0.10136205258156478,
      "grad_norm": 0.42251771688461304,
      "learning_rate": 4.9999755267102305e-05,
      "loss": 1.1444,
      "step": 80
    },
    {
      "epoch": 0.11403230915426038,
      "grad_norm": 0.34682685136795044,
      "learning_rate": 4.9970393116693784e-05,
      "loss": 1.0565,
      "step": 90
    },
    {
      "epoch": 0.12670256572695598,
      "grad_norm": 0.3825828433036804,
      "learning_rate": 4.9892150249148365e-05,
      "loss": 1.1083,
      "step": 100
    },
    {
      "epoch": 0.13937282229965156,
      "grad_norm": 0.37726879119873047,
      "learning_rate": 4.976517982855353e-05,
      "loss": 1.0319,
      "step": 110
    },
    {
      "epoch": 0.15204307887234716,
      "grad_norm": 0.3735262453556061,
      "learning_rate": 4.9589730405470165e-05,
      "loss": 1.0665,
      "step": 120
    },
    {
      "epoch": 0.16471333544504277,
      "grad_norm": 0.3597871959209442,
      "learning_rate": 4.936614543038305e-05,
      "loss": 1.0448,
      "step": 130
    },
    {
      "epoch": 0.17738359201773837,
      "grad_norm": 0.32837969064712524,
      "learning_rate": 4.9094862581380477e-05,
      "loss": 1.092,
      "step": 140
    },
    {
      "epoch": 0.19005384859043395,
      "grad_norm": 0.30468395352363586,
      "learning_rate": 4.877641290737884e-05,
      "loss": 0.9855,
      "step": 150
    },
    {
      "epoch": 0.20272410516312955,
      "grad_norm": 0.3451535403728485,
      "learning_rate": 4.84114197885694e-05,
      "loss": 0.9998,
      "step": 160
    },
    {
      "epoch": 0.21539436173582516,
      "grad_norm": 0.34309419989585876,
      "learning_rate": 4.800059771612233e-05,
      "loss": 1.0477,
      "step": 170
    },
    {
      "epoch": 0.22806461830852076,
      "grad_norm": 0.3534664213657379,
      "learning_rate": 4.754475089353667e-05,
      "loss": 1.0061,
      "step": 180
    },
    {
      "epoch": 0.24073487488121634,
      "grad_norm": 0.3915192186832428,
      "learning_rate": 4.704477166237422e-05,
      "loss": 1.0439,
      "step": 190
    },
    {
      "epoch": 0.25340513145391197,
      "grad_norm": 0.46160832047462463,
      "learning_rate": 4.650163875545903e-05,
      "loss": 1.0387,
      "step": 200
    },
    {
      "epoch": 0.2660753880266075,
      "grad_norm": 0.41821449995040894,
      "learning_rate": 4.591641538096193e-05,
      "loss": 0.988,
      "step": 210
    },
    {
      "epoch": 0.2787456445993031,
      "grad_norm": 0.39164209365844727,
      "learning_rate": 4.529024714112063e-05,
      "loss": 1.1113,
      "step": 220
    },
    {
      "epoch": 0.2914159011719987,
      "grad_norm": 0.4010550081729889,
      "learning_rate": 4.462435978966952e-05,
      "loss": 1.1164,
      "step": 230
    },
    {
      "epoch": 0.30408615774469433,
      "grad_norm": 0.4969339668750763,
      "learning_rate": 4.392005683236915e-05,
      "loss": 1.0332,
      "step": 240
    },
    {
      "epoch": 0.31675641431738993,
      "grad_norm": 0.4743172526359558,
      "learning_rate": 4.317871697533256e-05,
      "loss": 0.9972,
      "step": 250
    },
    {
      "epoch": 0.32942667089008554,
      "grad_norm": 0.40301182866096497,
      "learning_rate": 4.240179142614323e-05,
      "loss": 0.9969,
      "step": 260
    },
    {
      "epoch": 0.34209692746278114,
      "grad_norm": 0.49673718214035034,
      "learning_rate": 4.1590801053048194e-05,
      "loss": 0.968,
      "step": 270
    },
    {
      "epoch": 0.35476718403547675,
      "grad_norm": 0.5325896143913269,
      "learning_rate": 4.074733340778692e-05,
      "loss": 1.1318,
      "step": 280
    },
    {
      "epoch": 0.3674374406081723,
      "grad_norm": 0.434779554605484,
      "learning_rate": 3.987303961788429e-05,
      "loss": 1.0579,
      "step": 290
    },
    {
      "epoch": 0.3801076971808679,
      "grad_norm": 0.52615886926651,
      "learning_rate": 3.896963115449094e-05,
      "loss": 0.9975,
      "step": 300
    },
    {
      "epoch": 0.3927779537535635,
      "grad_norm": 0.4125142991542816,
      "learning_rate": 3.8038876482098045e-05,
      "loss": 1.029,
      "step": 310
    },
    {
      "epoch": 0.4054482103262591,
      "grad_norm": 0.47252240777015686,
      "learning_rate": 3.708259759668512e-05,
      "loss": 1.0104,
      "step": 320
    },
    {
      "epoch": 0.4181184668989547,
      "grad_norm": 0.3471682667732239,
      "learning_rate": 3.6102666459077264e-05,
      "loss": 0.9999,
      "step": 330
    },
    {
      "epoch": 0.4307887234716503,
      "grad_norm": 0.3569570481777191,
      "learning_rate": 3.510100133049396e-05,
      "loss": 1.0856,
      "step": 340
    },
    {
      "epoch": 0.4434589800443459,
      "grad_norm": 0.44388407468795776,
      "learning_rate": 3.407956301746266e-05,
      "loss": 0.9912,
      "step": 350
    },
    {
      "epoch": 0.4561292366170415,
      "grad_norm": 0.4469132423400879,
      "learning_rate": 3.304035103344792e-05,
      "loss": 0.9988,
      "step": 360
    },
    {
      "epoch": 0.46879949318973707,
      "grad_norm": 0.3529362976551056,
      "learning_rate": 3.1985399684709875e-05,
      "loss": 0.9701,
      "step": 370
    },
    {
      "epoch": 0.4814697497624327,
      "grad_norm": 0.5249046087265015,
      "learning_rate": 3.09167740880543e-05,
      "loss": 0.9902,
      "step": 380
    },
    {
      "epoch": 0.4941400063351283,
      "grad_norm": 0.46957337856292725,
      "learning_rate": 2.9836566128269315e-05,
      "loss": 0.9968,
      "step": 390
    },
    {
      "epoch": 0.5068102629078239,
      "grad_norm": 0.513690173625946,
      "learning_rate": 2.874689036316286e-05,
      "loss": 1.016,
      "step": 400
    },
    {
      "epoch": 0.5194805194805194,
      "grad_norm": 0.5097526907920837,
      "learning_rate": 2.764987988421634e-05,
      "loss": 0.9887,
      "step": 410
    },
    {
      "epoch": 0.532150776053215,
      "grad_norm": 0.56508469581604,
      "learning_rate": 2.6547682140957952e-05,
      "loss": 1.0018,
      "step": 420
    },
    {
      "epoch": 0.5448210326259106,
      "grad_norm": 0.5379127264022827,
      "learning_rate": 2.544245473722942e-05,
      "loss": 1.0569,
      "step": 430
    },
    {
      "epoch": 0.5574912891986062,
      "grad_norm": 0.4198804497718811,
      "learning_rate": 2.4336361207575066e-05,
      "loss": 1.0049,
      "step": 440
    },
    {
      "epoch": 0.5701615457713018,
      "grad_norm": 0.4701259732246399,
      "learning_rate": 2.323156678202139e-05,
      "loss": 0.9716,
      "step": 450
    },
    {
      "epoch": 0.5828318023439975,
      "grad_norm": 0.5307719111442566,
      "learning_rate": 2.2130234147537625e-05,
      "loss": 0.997,
      "step": 460
    },
    {
      "epoch": 0.5955020589166931,
      "grad_norm": 0.5249863266944885,
      "learning_rate": 2.10345192144744e-05,
      "loss": 0.9356,
      "step": 470
    },
    {
      "epoch": 0.6081723154893887,
      "grad_norm": 0.5629686117172241,
      "learning_rate": 1.9946566896268042e-05,
      "loss": 0.9957,
      "step": 480
    },
    {
      "epoch": 0.6208425720620843,
      "grad_norm": 0.5445113778114319,
      "learning_rate": 1.8868506910671722e-05,
      "loss": 1.0209,
      "step": 490
    },
    {
      "epoch": 0.6335128286347799,
      "grad_norm": 0.5325161218643188,
      "learning_rate": 1.7802449610733003e-05,
      "loss": 0.9529,
      "step": 500
    },
    {
      "epoch": 0.6461830852074755,
      "grad_norm": 0.46127647161483765,
      "learning_rate": 1.675048185367862e-05,
      "loss": 0.9613,
      "step": 510
    },
    {
      "epoch": 0.6588533417801711,
      "grad_norm": 0.5382518768310547,
      "learning_rate": 1.5714662915793466e-05,
      "loss": 0.9302,
      "step": 520
    },
    {
      "epoch": 0.6715235983528667,
      "grad_norm": 0.5704044699668884,
      "learning_rate": 1.4697020461290562e-05,
      "loss": 1.0409,
      "step": 530
    },
    {
      "epoch": 0.6841938549255623,
      "grad_norm": 0.5406962633132935,
      "learning_rate": 1.3699546573063148e-05,
      "loss": 0.9917,
      "step": 540
    },
    {
      "epoch": 0.6968641114982579,
      "grad_norm": 0.46808868646621704,
      "learning_rate": 1.2724193853088859e-05,
      "loss": 0.9782,
      "step": 550
    },
    {
      "epoch": 0.7095343680709535,
      "grad_norm": 0.6800073981285095,
      "learning_rate": 1.1772871600119651e-05,
      "loss": 1.0438,
      "step": 560
    },
    {
      "epoch": 0.722204624643649,
      "grad_norm": 0.5489380955696106,
      "learning_rate": 1.0847442072139847e-05,
      "loss": 1.0091,
      "step": 570
    },
    {
      "epoch": 0.7348748812163446,
      "grad_norm": 0.4971903860569,
      "learning_rate": 9.949716840908704e-06,
      "loss": 0.989,
      "step": 580
    },
    {
      "epoch": 0.7475451377890402,
      "grad_norm": 0.5864220261573792,
      "learning_rate": 9.081453245723568e-06,
      "loss": 0.9789,
      "step": 590
    },
    {
      "epoch": 0.7602153943617358,
      "grad_norm": 0.5629094243049622,
      "learning_rate": 8.244350953345731e-06,
      "loss": 0.9948,
      "step": 600
    },
    {
      "epoch": 0.7728856509344314,
      "grad_norm": 0.44914188981056213,
      "learning_rate": 7.440048630822883e-06,
      "loss": 0.9472,
      "step": 610
    },
    {
      "epoch": 0.785555907507127,
      "grad_norm": 0.3689987361431122,
      "learning_rate": 6.670120737721444e-06,
      "loss": 0.9957,
      "step": 620
    },
    {
      "epoch": 0.7982261640798226,
      "grad_norm": 0.5269716382026672,
      "learning_rate": 5.936074444048012e-06,
      "loss": 1.0761,
      "step": 630
    },
    {
      "epoch": 0.8108964206525182,
      "grad_norm": 0.4741295874118805,
      "learning_rate": 5.239346679893306e-06,
      "loss": 1.0176,
      "step": 640
    },
    {
      "epoch": 0.8235666772252138,
      "grad_norm": 0.47384387254714966,
      "learning_rate": 4.581301322574025e-06,
      "loss": 0.9958,
      "step": 650
    },
    {
      "epoch": 0.8362369337979094,
      "grad_norm": 0.5127732157707214,
      "learning_rate": 3.963226526778973e-06,
      "loss": 1.0291,
      "step": 660
    },
    {
      "epoch": 0.848907190370605,
      "grad_norm": 0.7115996479988098,
      "learning_rate": 3.3863322029457523e-06,
      "loss": 1.0397,
      "step": 670
    },
    {
      "epoch": 0.8615774469433006,
      "grad_norm": 0.44299933314323425,
      "learning_rate": 2.8517476488042427e-06,
      "loss": 0.9916,
      "step": 680
    },
    {
      "epoch": 0.8742477035159962,
      "grad_norm": 0.4516616761684418,
      "learning_rate": 2.3605193387232994e-06,
      "loss": 0.9801,
      "step": 690
    },
    {
      "epoch": 0.8869179600886918,
      "grad_norm": 0.48583275079727173,
      "learning_rate": 1.9136088751880137e-06,
      "loss": 0.989,
      "step": 700
    }
  ],
  "logging_steps": 10,
  "max_steps": 789,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 100,
  "total_flos": 1.609325567802409e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
